{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"JAVA_HOME\"] = '/Library/Java/JavaVirtualMachines/jdk1.8.0_144.jdk/Contents/Home/'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = 'pyspark-shell'\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = '/usr/local/Cellar/apache-spark/2.2.0/libexec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.environ['SPARK_HOME']+\"/python\")\n",
    "sys.path.append(os.environ['SPARK_HOME']+\"/python/lib/py4j-0.10.4-src.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import py4j\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.mllib.regression import LabeledPoint, LinearRegressionModel, LinearRegressionWithSGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf = (SparkConf().setMaster(\"local[8]\")\n",
    "        .setAppName(\"ML demo\")\n",
    "        .set(\"spark.executor.memory\", \"4g\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext(conf=conf)\n",
    "sql = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex|Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male| 22|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female| 38|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female| 26|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female| 35|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male| 35|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sql.read.format('com.databricks.spark.csv').options(header='true').load('train.csv')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, array\n",
    "from pyspark.sql import types\n",
    "\n",
    "def Embarked_transform(x):\n",
    "    if x != None:\n",
    "        return x\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "embarked_udf = udf(Embarked_transform, types.StringType())\n",
    "df = df.withColumn('Embarked', embarked_udf(df['Embarked']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "\n",
    "stringIndexer = StringIndexer(inputCol=\"Embarked\", outputCol=\"EmbarkedIndexed\")\n",
    "model = stringIndexer.fit(df)\n",
    "indexed = model.transform(df)\n",
    "encoder = OneHotEncoder(inputCol=\"EmbarkedIndexed\", outputCol=\"EmbarkedVec\")\n",
    "df_t = encoder.transform(indexed)\n",
    "df_t = df_t.drop('Embarked')\n",
    "df_t = df_t.drop('EmbarkedIndexed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_t = df_t.withColumn('Survived', df_t['Survived'].cast('int'))\n",
    "df_t = df_t.withColumn('Pclass', df_t['Pclass'].cast('int'))\n",
    "df_t = df_t.withColumn('Sex', df_t['Sex'] == 'male')\n",
    "df_t = df_t.withColumn('Parch', df_t['Parch'].cast('int'))\n",
    "df_t = df_t.withColumn('SibSp', df_t['SibSp'].cast('int'))\n",
    "df_t = df_t.withColumn('Fare', df_t['Fare'].cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticket_is_odd(x):\n",
    "    last_sym = x[-1]\n",
    "    if last_sym >= '0' and last_sym <= '9':\n",
    "        return int(last_sym) % 2\n",
    "    return -1\n",
    "\n",
    "def cabin_letter(x):\n",
    "    if x is None:\n",
    "        return ' '\n",
    "    else:\n",
    "        return x.split(' ')[0][0]\n",
    "\n",
    "udf_cabin_letter = udf(cabin_letter, types.StringType())\n",
    "udf_has_relatives = udf(lambda arr: arr[0]+arr[1]>0, types.BooleanType())\n",
    "udf_is_missis = udf(lambda x: 'Mrs.' in x, types.BooleanType())\n",
    "udf_is_miss = udf(lambda x: 'Ms.' in x, types.BooleanType())\n",
    "udf_ticket_is_odd = udf(ticket_is_odd, types.IntegerType())\n",
    "# udf_parse_age = udf(parse_age, types.FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = df_t.withColumn('IsMissis', udf_is_missis(df['Name']))\n",
    "df_t = df_t.withColumn('IsMiss', udf_is_miss(df['Name']))\n",
    "df_t = df_t.withColumn('HasRelatives', udf_has_relatives(array('Parch', 'SibSp')))\n",
    "df_t = df_t.withColumn('CabinLetter', udf_cabin_letter(df['Cabin']))\n",
    "df_t = df_t.withColumn('TicketIsOdd', udf_ticket_is_odd(df['Ticket']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+-----+---+-----+-----+----------------+-------+-----+-------------+--------+------+------------+-----------+-----------+\n",
      "|PassengerId|Survived|Pclass|                Name|  Sex|Age|SibSp|Parch|          Ticket|   Fare|Cabin|  EmbarkedVec|IsMissis|IsMiss|HasRelatives|CabinLetter|TicketIsOdd|\n",
      "+-----------+--------+------+--------------------+-----+---+-----+-----+----------------+-------+-----+-------------+--------+------+------------+-----------+-----------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...| true| 22|    1|    0|       A/5 21171|   7.25| null|(3,[0],[1.0])|   false| false|        true|           |          1|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|false| 38|    1|    0|        PC 17599|71.2833|  C85|(3,[1],[1.0])|    true| false|        true|          C|          1|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|false| 26|    0|    0|STON/O2. 3101282|  7.925| null|(3,[0],[1.0])|   false| false|       false|           |          0|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|false| 35|    1|    0|          113803|   53.1| C123|(3,[0],[1.0])|    true| false|        true|          C|          1|\n",
      "|          5|       0|     3|Allen, Mr. Willia...| true| 35|    0|    0|          373450|   8.05| null|(3,[0],[1.0])|   false| false|       false|           |          0|\n",
      "+-----------+--------+------+--------------------+-----+---+-----+-----+----------------+-------+-----+-------------+--------+------+------------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_t.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: boolean (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: float (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- EmbarkedVec: vector (nullable = true)\n",
      " |-- IsMissis: boolean (nullable = true)\n",
      " |-- IsMiss: boolean (nullable = true)\n",
      " |-- HasRelatives: boolean (nullable = true)\n",
      " |-- CabinLetter: string (nullable = true)\n",
      " |-- TicketIsOdd: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_t.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer(inputCol=\"CabinLetter\", outputCol=\"CabinLetterIndexed\")\n",
    "model = stringIndexer.fit(df_t)\n",
    "indexed = model.transform(df_t)\n",
    "encoder = OneHotEncoder(inputCol=\"CabinLetterIndexed\", outputCol=\"CabinLetterVec\")\n",
    "df_t = encoder.transform(indexed)\n",
    "df_t = df_t.drop('CabinLetter')\n",
    "df_t = df_t.drop('CabinLetterIndexed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_age(str_age):\n",
    "    try:\n",
    "        return float(str_age)\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transf(r):\n",
    "    return LabeledPoint(\n",
    "        r['Survived'],\n",
    "        [\n",
    "            r['Pclass'],\n",
    "            r['Sex'],\n",
    "            r['Fare'],\n",
    "            r['SibSp'],\n",
    "            r['Parch'],\n",
    "            parse_age(r['Age']),\n",
    "            r['IsMissis'],\n",
    "            r['IsMiss'],\n",
    "            r['HasRelatives'],\n",
    "            r['TicketIsOdd']\n",
    "        ] + list(r['CabinLetterVec'].toArray()) + list(r['EmbarkedVec'].toArray())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [3.0,1.0,7.25,1.0,0.0,22.0,0.0,0.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0]),\n",
       " LabeledPoint(1.0, [1.0,0.0,71.2833023071,1.0,0.0,38.0,1.0,0.0,1.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0]),\n",
       " LabeledPoint(1.0, [3.0,0.0,7.92500019073,0.0,0.0,26.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0]),\n",
       " LabeledPoint(1.0, [1.0,0.0,53.0999984741,1.0,0.0,35.0,1.0,0.0,1.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [3.0,1.0,8.05000019073,0.0,0.0,35.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df_t.rdd.map(transf)\n",
    "data.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[53] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = data.randomSplit([0.7, 0.3])\n",
    "train.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acc(model, test):\n",
    "    values = test.map(lambda x: x.features)\n",
    "    yhat = model.predict(values)\n",
    "    y = test.map(lambda x: x.label)\n",
    "    comp = yhat.zip(y)\n",
    "    errors = comp.map(lambda x: abs(x[0]-x[1]))\n",
    "    return 1-errors.sum()/errors.count()\n",
    "\n",
    "def f1(model, test):\n",
    "    values = test.map(lambda x: x.features)\n",
    "    yhat = model.predict(values)\n",
    "    y = test.map(lambda x: x.label)\n",
    "    comp = yhat.zip(y)\n",
    "    fn = comp.map(lambda x: 1 if (x[1] == 1) & (x[0] == 0) else 0).sum()\n",
    "    fp = comp.map(lambda x: 1 if (x[1] == 0) & (x[0] == 1) else 0).sum()\n",
    "    tp = comp.map(lambda x: 1 if (x[1] == 1) & (x[0] == 1) else 0).sum()\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import RandomForestModel, RandomForest, GradientBoostedTreesModel, GradientBoostedTrees\n",
    "from pyspark.mllib.classification import SVMModel, SVMWithSGD, LogisticRegressionWithLBFGS, LogisticRegressionModel, LogisticRegressionWithLBFGS\n",
    "\n",
    "rfc = RandomForest.trainClassifier(train, numClasses=2, categoricalFeaturesInfo={}, numTrees=100)\n",
    "lreg = LogisticRegressionWithLBFGS.train(train)\n",
    "svm = SVMWithSGD.train(train)\n",
    "gbt = GradientBoostedTrees.trainClassifier(train, categoricalFeaturesInfo={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest accuracy: 0.801, f1: 0.683\n",
      "Logistic regression accuracy: 0.789, f1: 0.696\n",
      "SVM accuracy: 0.658, f1: 0.616\n",
      "Gradient boosting accuracy: 0.793, f1: 0.689\n"
     ]
    }
   ],
   "source": [
    "print('Random forest accuracy: {:.3f}, f1: {:.3f}'.format(acc(rfc, test), f1(rfc, test)))\n",
    "print('Logistic regression accuracy: {:.3f}, f1: {:.3f}'.format(acc(lreg, test), f1(lreg, test)))\n",
    "print('SVM accuracy: {:.3f}, f1: {:.3f}'.format(acc(svm, test), f1(svm, test)))\n",
    "print('Gradient boosting accuracy: {:.3f}, f1: {:.3f}'.format(acc(gbt, test), f1(gbt, test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
